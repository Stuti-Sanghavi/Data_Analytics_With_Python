{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1 : Sentiment Analysis on Twitter\n",
    "\n",
    "### Submission By: Stuti Sanghavi\n",
    "### Student Id : 00001587699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the outputs in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Using the keyword 'Trump'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------- Defining a function to import data --------------------------------------------#\n",
    "\n",
    "def import_data (filename):\n",
    "    \n",
    "    #Open a connection with the file\n",
    "    file = open(filename, mode = 'r')\n",
    "    \n",
    "    #Reading the data\n",
    "    data = file.read()\n",
    "    \n",
    "    #Closing the file connection\n",
    "    file.close()\n",
    "    \n",
    "    #Returning the data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Trump Tweet data (Text file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"RT @TheRickWilson: 1/ I\\'ll summarize this for the slow learners in the Senate one last time. \\\\n\\\\nYour protestations of independence, integrit\\\\xe2\\\\x80\\\\xa6\\\\n\"b\\'RT @alexespind: Madame Speaker is correct. There\\\\xe2\\\\x80\\\\x99s a #GopCoverup . Let\\\\xe2\\\\x80\\\\x99s get it trending. https://t.co/zChKIc6GzP\\\\n\\'b\"RT @RepAdamSchiff: Trump\\'s lawyer claimed the House isn\\'t ready to present our case.\\\\n\\\\nWe\\\\xe2\\\\x80\\\\x99re ready.\\\\n\\\\nThe House calls John Bolton to testify.\\\\xe2\\\\x80\\\\xa6\\\\n\"b\\'RT @Jamierodr14: GOOD! \\\\n\\\\nRI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Trump.txt file by calling the function import_data\n",
    "\n",
    "tweet_data = import_data('Trump.txt')\n",
    "\n",
    "# Checking part of the data to see if imported correctly\n",
    "tweet_data[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Removing the @mentions in the tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing @mentions\n",
    "\n",
    "tweet_data_2 = re.sub(r'@[A-Za-z0-9]+','',tweet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Removing url links from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing url links\n",
    "\n",
    "tweet_data_3 = re.sub('https?://[A-Za-z0-9./]+','',tweet_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Removing new line, breaks, retweets etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing new line, breaks, retweets with blank spaces\n",
    "\n",
    "tweet_data_4 = tweet_data_3.replace('\\n',' ').replace('\\'b',' ').replace('\\'RT',' ').replace('\\\\n', ' ').replace('\"RT',' ').replace('\"b',' ').replace('https:/',' ').replace('_','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Removing emoticons (eg. \\\\xe2\\\\x80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing emoticons\n",
    "\n",
    "tweet_data_5 = re.sub(r'\\\\[a-z0-9A-Z]+','',tweet_data_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Removing hashtags, punctuations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting rid of hashtags and punctuations\n",
    "\n",
    "tweet_data_6 = re.sub(r'[^\\w\\s]','',tweet_data_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. Removing numbers from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing numbers from data\n",
    "\n",
    "tweet_data_7 = re.sub(r'[0-9]+','',tweet_data_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g. Converting all the data to lowercase for getting the final cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b    ill summarize this for the slow learners in the senate one last time   your protestations of independence integrit     madame speaker is correct there a gopcoverup  let get it trending      trumps lawyer claimed the house isnt ready to present our case  we ready  the house calls john bolton to '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting data to lower case \n",
    "tweet_data_cleaned = tweet_data_7.lower()\n",
    "\n",
    "#Displaying first 300 characters of the cleaned data\n",
    "tweet_data_cleaned[0:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the clean data in form of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'slow',\n",
       " 'learners',\n",
       " 'in',\n",
       " 'the',\n",
       " 'senate',\n",
       " 'one',\n",
       " 'last',\n",
       " 'time',\n",
       " 'your']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "236233"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the cleaned tweet data stored in a list form\n",
    "tweet_list = tweet_data_cleaned.strip().split()\n",
    "\n",
    "# Displaying only 10 words of the list\n",
    "tweet_list[5:15]\n",
    "\n",
    "#Displaying cleaned word count\n",
    "len(tweet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing positive, negative and stop words list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Importing positive words list by calling the function import_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = import_data('positive.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Converting the text file to list and displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'accessable',\n",
       " 'accessible',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclamation']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the text file(positive_words) to a list\n",
    "positive_list = positive_words.strip().split()\n",
    "\n",
    "#Displaying only the first 10 words from the positive list\n",
    "positive_list[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Importing negative words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = import_data('negative.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Converting the text file to list and displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced',\n",
       " '2-faces',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the text file(negative_words) to a list\n",
    "negative_list = negative_words.strip().split()\n",
    "\n",
    "# Displaying only the first 10 words from the negative list\n",
    "negative_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Importing stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = import_data('stop.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. Converting the text file to list and displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the text file(stop_words) to a list\n",
    "stop_list = stop_words.strip().split()\n",
    "\n",
    "#Displaying only the first 10 words from the stop list\n",
    "stop_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a loop for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined a function called sentiments, which takes input of tweet_data, positive words, neagtive words and stop words.\n",
    "The counters for positive, negative, stop and others have been set to 0. After which, a 'for' loop is run, in which, for a word in the tweet_data if the word is found in the positive, then the counter for positive words will increase by 1. Similarly, the counters for negative, stop and others would increase if the word from the tweet data is found in any of the word list. This will continue till all the words from the tweet_list are counted. Once that is done, the loop returns the count for each word type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function called sentiments for counting, positive, negative, stop and other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function called sentiments for categorizing and counting, positive, negative, stop and other words\n",
    "\n",
    "def sentiments(tweet_list, positive_list, negative_list, stop_list):\n",
    "    count_positive = 0\n",
    "    count_negative = 0\n",
    "    count_stop = 0\n",
    "    count_others = 0\n",
    "\n",
    "    for word in tweet_list:\n",
    "        if word in positive_list:\n",
    "            count_positive += 1\n",
    "        elif word in negative_list:\n",
    "            count_negative += 1\n",
    "        elif word in stop_list:\n",
    "            count_stop += 1\n",
    "        else:\n",
    "            count_others += 1\n",
    "    \n",
    "    all_counts = [count_positive,count_negative, count_stop, count_others]\n",
    "    return all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14728, 9170, 104523, 107812]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the sentiments function on tweet data\n",
    "\n",
    "total_counts = sentiments(tweet_list, positive_list, negative_list, stop_list)\n",
    "total_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ratio and percentage of positive/total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of positive to total word count is 0.06234522695813032\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of positive to total word count is \" + str(total_counts[0]/len(tweet_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive word count is 6.234522695813032\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of positive word count is \" + str(total_counts[0]/len(tweet_list)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ratio and percentage of negative/total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of negative to total word count is 0.03881760803952031\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of negative to total word count is \" + str(total_counts[1]/len(tweet_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of negative word count is 3.8817608039520306\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of negative word count is \" + str(total_counts[1]/len(tweet_list)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ratio and percentage of stop/total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of stop to total word count is 0.4424572350179696\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of stop to total word count is \" + str(total_counts[2]/len(tweet_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of stop word count is 44.24572350179696\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of stop word count is \" + str(total_counts[2]/len(tweet_list)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ratio and percentage of other/total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of other to total word count is 0.4563799299843798\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of other to total word count is \" + str(total_counts[3]/len(tweet_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of other word count is 45.63799299843798\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of other word count is \" + str(total_counts[3]/len(tweet_list)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function called sentiment output for interpreting the sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined a function called sentiment_output, which takes input of positive count and negative count. Then there is an if else statement which is used to categorize and analyze the sentiment attached to every word. \n",
    "- If the count_positive >= 1.75 that of negative then it is a very strong positive sentiment and it will print the same\n",
    "- Similarly, there are other conditions used to categorize sentiment as mildly positive, neutral, strongly negative and mildly negative.\n",
    "- If one of the condition in the if statement is not satisfied, it will go on to the next, until one of the conditions is satisfied and it throws an ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function called sentiment_output for interpreting the sentiment and categorizing it\n",
    "\n",
    "def sentiment_output(count_positive, count_negative):\n",
    "    if count_positive >= 1.75 * count_negative:\n",
    "        print(\"The sentiment is Strongly positive\")\n",
    "    elif count_positive >= 1.10 * count_negative:\n",
    "        print(\"The sentiment is Mildly positive\")\n",
    "    elif count_negative >= 1.75 * count_positive:\n",
    "        print(\"The sentiment is Strongly negative\")\n",
    "    elif count_negative >= 1.10 * count_positive:\n",
    "        print(\"The sentiment is Mildly negative\")\n",
    "    else:\n",
    "        print(\"The sentiment is Neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the sentiment_output function below to see the nature of the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is Mildly positive\n"
     ]
    }
   ],
   "source": [
    "#Inputting the positive and negative word counts\n",
    "sentiment_output(total_counts[0], total_counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the result from above, by taking the ratio of total positive to total negative word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.61"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = total_counts[0]/total_counts[1]\n",
    "round(output,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the ratio as 1.61, which falls under the range of mildly positive (as defined above) and hence, the result is verified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting list to tuple and running %timeit on it to check which one takes lesser time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------Using tuples instead of lists------------------------------------------#\n",
    "\n",
    "tweet_tuple = tuple(tweet_list)\n",
    "positive_tuple = tuple(positive_list)\n",
    "negative_tuple = tuple(negative_list)\n",
    "stop_tuple = tuple(stop_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.4 s ± 691 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "34.1 s ± 964 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#--------------------------- Running %timeit on it to check which runs faster---------------------------------------------#\n",
    "\n",
    "%timeit sentiments(tweet_tuple, positive_tuple, negative_tuple, stop_tuple)\n",
    "%timeit sentiments(tweet_list, positive_list, negative_list, stop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running %timeit on tuple and list, and comparing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: The overall sentiment is mildly positive for the keyword Trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : For the keyword \"Schiff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Tweet data (Text file) by using the import_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\\'RT @Trump2Usa: \"Ridiculous!\" - Trump Lead Impeachment Lawyer Pat Cipollone DESTROYS Schiff (VIDEO) https://t.co/nx1qpYLxhW\\\\n\\'b\\'RT @RubenGallego: The Vice President\\\\xe2\\\\x80\\\\x99s brother had access to the SCIF and Intel. He sits on one of the three Committees that were allowed i\\\\xe2\\\\x80\\\\xa6\\\\n\\'b\\'RT @JRubinBlogger: In his calm and methodical presentation, Schiff scored a victory: Democrats have effectively built the case that the Sen\\\\xe2\\\\x80\\\\xa6\\\\n\\'b\"RT @RepAndyBiggsAZ: Schiff Argument #1: We can\\'t'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Schiff.txt file by calling the function import_data\n",
    "\n",
    "tweet_data_schiff = import_data('Schiff.txt')\n",
    "\n",
    "# Checking part of the data to see if imported correctly\n",
    "tweet_data_schiff[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b   ridiculous  trump lead impeachment lawyer pat cipollone destroys schiff video      the vice president brother had access to the scif and intel he sits on one of the three committees that were allowed i     in his calm and methodical presentation schiff scored a victory democrats have effectively built the case that the sen     schiff argument  we cant have a fair senate trial wo the documents amp witnesses we didnt call in the house when we  schiff and all the dem aholes hate our president s'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------ Cleaning the data ----------------------------------------------------\n",
    "\n",
    "# Removing @mentions in the data\n",
    "tweet_data1 = re.sub(r'@[A-Za-z0-9]+','',tweet_data_schiff)\n",
    "\n",
    "#Removing url links from the data\n",
    "tweet_data2 = re.sub('https?://[A-Za-z0-9./]+','',tweet_data1)\n",
    "\n",
    "#Removing the new line, breaks, retweets etc.\n",
    "tweet_data3 = tweet_data2.replace('\\n',' ').replace('\\'b',' ').replace('\\'RT',' ').replace('\\\\n', ' ').replace('\"RT',' ').replace('\"b',' ').replace('https:/',' ').replace('_','')\n",
    "\n",
    "# Removing emoticons (eg. \\xe2\\x80)\n",
    "tweet_data4 = re.sub(r'\\\\[a-z0-9A-Z]+','',tweet_data3)\n",
    "\n",
    "#Removing hashtags, punctuations, etc.\n",
    "tweet_data5 = re.sub(r'[^\\w\\s]','',tweet_data4)\n",
    "\n",
    "#Removing numbers from the data\n",
    "tweet_data6 = re.sub(r'[0-9]+','',tweet_data5)\n",
    "\n",
    "#Converting all the data to lowercase for getting the final cleaned file\n",
    "schiff_data_cleaned = tweet_data6.lower()\n",
    "\n",
    "#Displaying first 500 characters of the cleaned data\n",
    "schiff_data_cleaned[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the clean data in form of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lawyer',\n",
       " 'pat',\n",
       " 'cipollone',\n",
       " 'destroys',\n",
       " 'schiff',\n",
       " 'video',\n",
       " 'the',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'brother']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "241943"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the cleaned data into a list of words by splitting the data\n",
    "schiff_data_list = schiff_data_cleaned.strip().split()\n",
    "\n",
    "# Displaying only 10 words of the list\n",
    "schiff_data_list[5:15]\n",
    "\n",
    "#Displaying cleaned word count\n",
    "len(schiff_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a loop for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the same list of positive, negative and stop words and run a for loop on the cleaned data using those lists. For doing that, we do not need to code the same thing again, but merely calling the sentiment function with the schiff_data_list as the input along with the other lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8075, 11165, 105037, 117666]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the sentiments function on schiff_data_list\n",
    "\n",
    "total_counts_schiff = sentiments(schiff_data_list, positive_list, negative_list, stop_list)\n",
    "total_counts_schiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ratio and percentage of positive/total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of positive to total word count is 0.03337562979710097\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of positive to total word count is \" + str(total_counts_schiff[0]/len(schiff_data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive word count is 3.337562979710097\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of positive word count is \" + str(total_counts_schiff[0]/len(schiff_data_list)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ratio and percentage of negative/total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of negative to total word count is 0.04614723302596066\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of negative to total word count is \" + str(total_counts_schiff[1]/len(schiff_data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of negative word count is 4.614723302596066\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of negative word count is \" + str(total_counts_schiff[1]/len(schiff_data_list)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ratio and percentage of stop/total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of stop to total word count is 0.43413944606787547\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of stop to total word count is \" + str(total_counts_schiff[2]/len(schiff_data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of stop word count is 43.413944606787545\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of stop word count is \" + str(total_counts_schiff[2]/len(schiff_data_list)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ratio and percentage of other/total word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of other to total word count is 0.4863376911090629\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of other to total word count is \" + str(total_counts_schiff[3]/len(schiff_data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of other word count is 48.633769110906286\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of other word count is \" + str(total_counts_schiff[3]/len(schiff_data_list)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the sentiment_output function from above to see the nature of the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is Mildly negative\n"
     ]
    }
   ],
   "source": [
    "#Inputting the positive and negative word counts\n",
    "sentiment_output(total_counts_schiff[0], total_counts_schiff[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the result from above, by taking the ratio of total negative to total positive word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.38"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = total_counts_schiff[1]/total_counts_schiff[0]\n",
    "round(output,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We get the ratio as 1.38, which falls under the range of mildly negative (as defined in the function above) and hence, the result is verified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting list to tuple and running %timeit on it to check which one takes lesser time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------Using tuples instead of lists------------------------------------------#\n",
    "\n",
    "schiff_data_tuple = tuple(schiff_data_list)\n",
    "\n",
    "# We do not need to convert positive, negative or stop word list to tuple since they are already converted in part 1 \n",
    "# and hence we can use the same tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.2 s ± 2.33 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "35.2 s ± 1.98 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#--------------------------- Running %timeit on it to check which runs faster---------------------------------------------#\n",
    "\n",
    "%timeit sentiments(schiff_data_tuple, positive_tuple, negative_tuple, stop_tuple)\n",
    "%timeit sentiments(schiff_data_list, positive_list, negative_list, stop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running %timeit on tuple and list, and comparing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: The overall sentiment is mildly negative for the keyword Schiff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
